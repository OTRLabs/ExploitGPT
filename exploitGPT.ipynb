{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExploitGPT\n",
    "## An AI-based Research Assistant for Offensive Security\n",
    "---\n",
    "\n",
    "# Table of Contents\n",
    "- [Introduction](#introduction)\n",
    "  - [What is ExploitGPT?](#what-is-exploitgpt)\n",
    "  - [How does it work?](#how-does-it-work)\n",
    "  - [Structure of the zip file](#structure-of-the-zip-file)\n",
    "  - [Example](#example)\n",
    "- [Installation](#installation)\n",
    "- [Usage](#usage)\n",
    "- [Limitations](#limitations)\n",
    "- [Future Work](#future-work)\n",
    "- [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### What is ExploitGPT?\n",
    "ExploitGPT is an AI-powered tool designed to assist in the offensive security domain. It turns data from the recon phase into a detailed plan for gaining initial access to a target.\n",
    "\n",
    "### How does it work?\n",
    "ExploitGPT utilizes a variety of AI/ML tools to generate a comprehensive plan for gaining initial access to a target. It intakes recon data, which is provided in the form of a structured zip file, and processes it to create actionable insights.\n",
    "\n",
    "### Structure of the zip file\n",
    "The zip file is structured as follows:\n",
    "```bash\n",
    "user@machine:~/ExploitGPT$ tree example\n",
    "example\n",
    "├── hosts.md\n",
    "├── index.json\n",
    "├── internet_presence.md\n",
    "├── people.md\n",
    "└── services.md\n",
    "\n",
    "0 directories, 5 files\n",
    "\n",
    "```\n",
    "This zip file contains the following data:\n",
    "\n",
    "- `hosts.md`: Information about the hosts\n",
    "- `index.json`: Index of the recon data\n",
    "- `internet_presence.md`: Details about the internet presence\n",
    "- `people.md`: Information about relevant people\n",
    "- `services.md`: Information about services running on the hosts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
